{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST (\"Modified National Institute of Standards and Technology\") is the de facto “hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\n",
    "\n",
    "In this competition, your goal is to correctly identify digits from a dataset of tens of thousands of handwritten images. We’ve curated a set of tutorial-style kernels which cover everything from regression to neural networks. We encourage you to experiment with different algorithms to learn first-hand what works well and how techniques compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shwetakumari/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/shwetakumari/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/shwetakumari/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/shwetakumari/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/shwetakumari/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/shwetakumari/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/shwetakumari/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/shwetakumari/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/shwetakumari/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/shwetakumari/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/shwetakumari/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/shwetakumari/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "training_d=pd.read_csv('train_mnist.csv')\n",
    "testing_d=pd.read_csv('test_mnist.csv')\n",
    "training_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 784), (28000, 784), (42000, 10))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=pd.get_dummies(training_d.label) #to convert into one hot encoded\n",
    "training_d.drop('label',inplace=True,axis=1)\n",
    "training_d.shape,testing_d.shape,labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###plot image\n",
    "image=training_d.iloc[1]\n",
    "image=np.array(image,dtype='float')\n",
    "image=image.reshape((28,28))\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USING TENSORFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-050badf6477e>:25: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "n_input=784\n",
    "n_hidden1=512\n",
    "n_hidden2=256\n",
    "n_classes=10\n",
    "epsilon=1e-3\n",
    "weights={'h1':tf.Variable(tf.random_normal([n_input,n_hidden1])),\n",
    "         'h2':tf.Variable(tf.random_normal([n_hidden1,n_hidden2])),\n",
    "        'out':tf.Variable(tf.random_normal([n_hidden2,n_classes]))}\n",
    "biases={'h1':tf.Variable(tf.random_normal([n_hidden1])),\n",
    "         'h2':tf.Variable(tf.random_normal([n_hidden2])),\n",
    "        'out':tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "###forward propagation\n",
    "def forward_propagation(x,weights,biases):\n",
    "    ###w^t*x+b\n",
    "    in_layer1=tf.add(tf.matmul(x,weights['h1']),biases['h1'])\n",
    "    ###batch normalization\n",
    "    batch_mean_1,batch_var_1=tf.nn.moments(in_layer1,[0])\n",
    "    scale_1=tf.Variable(tf.ones([n_hidden1]))\n",
    "    beta_1=tf.Variable(tf.zeros([n_hidden1]))\n",
    "    layer_1=tf.nn.batch_normalization(in_layer1,batch_mean_1,batch_var_1,beta_1,scale_1,epsilon)\n",
    "    ###activation fn\n",
    "    out_layer1=tf.nn.relu(layer_1)\n",
    "    ###dropout layer\n",
    "    out_layer1_drop=tf.nn.dropout(out_layer1,keep_prob)\n",
    "    ###same for layer2\n",
    "    in_layer2=tf.add(tf.matmul(out_layer1_drop,weights['h2']),biases['h2'])\n",
    "    batch_mean_2,batch_var_2=tf.nn.moments(in_layer2,[0])\n",
    "    scale_2=tf.Variable(tf.ones([n_hidden2]))\n",
    "    beta_2=tf.Variable(tf.zeros([n_hidden2]))\n",
    "    layer_2=tf.nn.batch_normalization(in_layer2,batch_mean_2,batch_var_2,beta_2,scale_2,epsilon)\n",
    "    out_layer2=tf.nn.relu(in_layer2) \n",
    "    out_layer2_drop=tf.nn.dropout(out_layer2,keep_prob)\n",
    "    ###output layer\n",
    "    output=tf.add(tf.matmul(out_layer2,weights['out']),biases['out'])\n",
    "    return output\n",
    "\n",
    "x=tf.placeholder('float',[None,n_input])\n",
    "y=tf.placeholder('int32',[None,n_classes])\n",
    "keep_prob=tf.placeholder('float32')\n",
    "pred=forward_propagation(x,weights,biases)\n",
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred,labels=y))\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "optimize=optimizer.minimize(cost)\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size=100\n",
    "for i in range(25): ###training epochs= 25\n",
    "    num_batches=int(len(training_d)/batch_size)\n",
    "    total_cost=0\n",
    "    l=0\n",
    "    for j in range(num_batches):\n",
    "        batch_x=training_d[l:l+batch_size]\n",
    "        batch_y=labels[l:l+batch_size]\n",
    "        l+=batch_size\n",
    "        c,opt=sess.run([cost,optimize],feed_dict={x:batch_x,y:batch_y,keep_prob: 0.5})\n",
    "        total_cost+=c\n",
    "    print(total_cost)\n",
    "    #c,opt=sess.run([cost,optimize],feed_dict={x:training_d,y:labels})\n",
    "\n",
    "predictions1=tf.argmax(pred,1)\n",
    "predictions1=sess.run([predictions1],feed_dict={x:testing_d})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_=np.arange(1,len(testing_d)+1)\n",
    "op = pd.DataFrame({'ImageId':id_, 'Label':predictions1[0]})\n",
    "op.to_csv('kaggle_digit_recognizer.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USING CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_width=28\n",
    "input_height=28\n",
    "input_channels=1\n",
    "input_pixels=784\n",
    "n_conv1=32\n",
    "n_conv2=64\n",
    "conv1_k=5\n",
    "conv2_k=5\n",
    "n_hidden=1024\n",
    "n_out=10\n",
    "max_pool1_k=2\n",
    "max_pool2_k=2\n",
    "stride_conv1=1\n",
    "stride_conv2=1\n",
    "input_size_to_hidden=(input_width//(max_pool1_k*max_pool2_k)*(input_height//(max_pool1_k*max_pool2_k)))*n_conv2\n",
    "weights={'wc1':tf.Variable(tf.random_normal([conv1_k,conv1_k,input_channels,n_conv1])),\n",
    "         'wc2':tf.Variable(tf.random_normal([conv2_k,conv2_k,n_conv1,n_conv2])),\n",
    "         'wh1':tf.Variable(tf.random_normal([input_size_to_hidden,n_hidden])),\n",
    "         'wo':tf.Variable(tf.random_normal([n_hidden,n_out]))}\n",
    "biases={'bc1':tf.Variable(tf.random_normal([n_conv1])),\n",
    "        'bc2':tf.Variable(tf.random_normal([n_conv2])),\n",
    "        'bh1':tf.Variable(tf.random_normal([n_hidden])),\n",
    "        'bo':tf.Variable(tf.random_normal([n_out]))}\n",
    "\n",
    "def cnn(x,weights,biases):\n",
    "    x=tf.reshape(x,shape=[-1,input_height,input_width,input_channels])\n",
    "    conv1=conv(x,weights['wc1'],biases['bc1'],stride_conv1)\n",
    "    conv1_pool=maxpooling(conv1,max_pool1_k)\n",
    "    conv2=conv(conv1_pool,weights['wc2'],biases['bc2'],stride_conv2)\n",
    "    conv2_pool=maxpooling(conv2,max_pool2_k)\n",
    "    hidden_input=tf.reshape(conv2_pool,shape=[-1,input_size_to_hidden])\n",
    "    hidden_output_before_activation=tf.add(tf.matmul(hidden_input,weights['wh1']),biases['bh1'])\n",
    "    hidden_output=tf.nn.relu(hidden_output_before_activation)\n",
    "    output=tf.add(tf.matmul(hidden_output,weights['wo']),biases['bo'])\n",
    "    return output\n",
    "\n",
    "def conv(x,weights,biases,strides=1):\n",
    "        out=tf.nn.conv2d(x,weights,padding='SAME',strides=[1,strides,strides,1])\n",
    "        out=tf.nn.bias_add(out,biases)\n",
    "        out=tf.nn.relu(out)\n",
    "        return out\n",
    "\n",
    "def maxpooling(x,k=2):\n",
    "    return tf.nn.max_pool(x,padding='SAME',ksize=[1,k,k,1],strides=[1,k,k,1])\n",
    "\n",
    "x=tf.placeholder('float',[None,input_pixels])\n",
    "y=tf.placeholder('int32',[None,n_out])\n",
    "\n",
    "pred=cnn(x,weights,biases) #forward propagation\n",
    "\n",
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred,labels=y))\n",
    "\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "optimize=optimizer.minimize(cost)\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size=100\n",
    "for i in range(25):\n",
    "    num_batches=int(len(training_d)/batch_size)\n",
    "    total_cost=0\n",
    "    l=0\n",
    "    for j in range(num_batches):\n",
    "        batch_x=training_d[l:l+batch_size]\n",
    "        batch_y=labels[l:l+batch_size]\n",
    "        l+=batch_size\n",
    "        c,opt=sess.run([cost,optimize],feed_dict={x:batch_x,y:batch_y})\n",
    "        total_cost+=c\n",
    "    print(total_cost)\n",
    "    c,opt=sess.run([cost,optimize],feed_dict={x:training_d,y:labels})\n",
    "    \n",
    "predictions2=tf.argmax(pred,1)\n",
    "predictions2=sess.run([predictions2],feed_dict={x:testing_d})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_=np.arange(1,len(testing_d)+1)\n",
    "op = pd.DataFrame({'ImageId':id_, 'Label':predictions2[0]})\n",
    "op.to_csv('kaggle_digit_recognizer.csv', index=False)\n",
    "\n",
    "####96.4 % accuracy on kaggle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
